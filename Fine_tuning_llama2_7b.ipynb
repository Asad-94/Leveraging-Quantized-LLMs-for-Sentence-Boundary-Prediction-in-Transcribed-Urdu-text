{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Llama2-7b using QLoRA method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:15:31.449601Z",
     "iopub.status.busy": "2023-12-25T14:15:31.449051Z",
     "iopub.status.idle": "2023-12-25T14:17:40.936362Z",
     "shell.execute_reply": "2023-12-25T14:17:40.935050Z",
     "shell.execute_reply.started": "2023-12-25T14:15:31.449573Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -q huggingface_hub\n",
    "!pip install -q -U trl transformers accelerate peft\n",
    "!pip install -q -U datasets bitsandbytes einops wandb\n",
    "!pip install git+https://github.com/huggingface/peft.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:18:04.511010Z",
     "iopub.status.busy": "2023-12-25T14:18:04.510101Z",
     "iopub.status.idle": "2023-12-25T14:18:04.977507Z",
     "shell.execute_reply": "2023-12-25T14:18:04.976559Z",
     "shell.execute_reply.started": "2023-12-25T14:18:04.510970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dab9b36b7047d98195405c8306ff92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading & Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:18:38.594970Z",
     "iopub.status.busy": "2023-12-25T14:18:38.594583Z",
     "iopub.status.idle": "2023-12-25T14:20:31.702813Z",
     "shell.execute_reply": "2023-12-25T14:20:31.701945Z",
     "shell.execute_reply.started": "2023-12-25T14:18:38.594939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1124cee2494024b5e15f40b6ed63c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce7d64157724e6fb120b21739a47df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d281c8a930f48bc9ab941d0a5701686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432d03231f7a4e418f372977a6eca7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953c6f52ef6d40668a549a8ba58ce401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a47d61d7b4d88bb36b72e2a9430b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c32f0e877cc4b24a39932343b51fd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    " load_in_4bit=True,\n",
    " bnb_4bit_use_double_quant=True,\n",
    " bnb_4bit_quant_type=\"nf4\",\n",
    " bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "foundation_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    " quantization_config=bnb_config,\n",
    " device_map=device_map,\n",
    " use_cache = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:11:59.872324Z",
     "iopub.status.busy": "2023-12-17T07:11:59.871445Z",
     "iopub.status.idle": "2023-12-17T07:12:02.337174Z",
     "shell.execute_reply": "2023-12-17T07:12:02.336370Z",
     "shell.execute_reply.started": "2023-12-17T07:11:59.872280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61891fb4434162b27eb0a015fc4927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90432ce4fa3e45e381666ad2a58f4234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.97M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95db6ee03954461828939cd1d0c3798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48585234e5ca4809b9b1e27ede5ff86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"Asad182/train_sentences\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:12:15.437943Z",
     "iopub.status.busy": "2023-12-17T07:12:15.437307Z",
     "iopub.status.idle": "2023-12-17T07:12:15.444405Z",
     "shell.execute_reply": "2023-12-17T07:12:15.443532Z",
     "shell.execute_reply.started": "2023-12-17T07:12:15.437910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking shape of the data\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting QLoRA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T19:40:40.524833Z",
     "iopub.status.busy": "2023-12-20T19:40:40.524456Z",
     "iopub.status.idle": "2023-12-20T19:40:40.530058Z",
     "shell.execute_reply": "2023-12-20T19:40:40.529000Z",
     "shell.execute_reply.started": "2023-12-20T19:40:40.524802Z"
    }
   },
   "outputs": [],
   "source": [
    "import peft\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    " r=16, \n",
    " lora_alpha=16, \n",
    " lora_dropout=0.05, \n",
    " bias=\"none\", \n",
    " task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:12:26.536570Z",
     "iopub.status.busy": "2023-12-17T07:12:26.535792Z",
     "iopub.status.idle": "2023-12-17T07:12:26.541069Z",
     "shell.execute_reply": "2023-12-17T07:12:26.540175Z",
     "shell.execute_reply.started": "2023-12-17T07:12:26.536527Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a directory to contain the Model\n",
    "import os\n",
    "working_dir = './Fine_tuning_urdu'\n",
    "\n",
    "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:12:32.949047Z",
     "iopub.status.busy": "2023-12-17T07:12:32.948370Z",
     "iopub.status.idle": "2023-12-17T07:12:32.957707Z",
     "shell.execute_reply": "2023-12-17T07:12:32.956925Z",
     "shell.execute_reply.started": "2023-12-17T07:12:32.949012Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating the TrainingArgs\n",
    "import transformers\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    " output_dir=output_directory,\n",
    " auto_find_batch_size=True,\n",
    " learning_rate= 2e-4, \n",
    " num_train_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:20:41.618827Z",
     "iopub.status.busy": "2023-12-25T14:20:41.618451Z",
     "iopub.status.idle": "2023-12-25T14:20:42.468791Z",
     "shell.execute_reply": "2023-12-25T14:20:42.467953Z",
     "shell.execute_reply.started": "2023-12-25T14:20:41.618788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cb87726da947f39b8c32801375f960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e144d5495c984c3995448b7aba28ae28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fdf3f1bef94817aad0feb2f920e6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7f2c051a96447fb50481b2239fb13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Output Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:20:58.753278Z",
     "iopub.status.busy": "2023-12-25T14:20:58.752861Z",
     "iopub.status.idle": "2023-12-25T14:20:58.759232Z",
     "shell.execute_reply": "2023-12-25T14:20:58.758228Z",
     "shell.execute_reply.started": "2023-12-25T14:20:58.753246Z"
    }
   },
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "\n",
    "def get_outputs(model, inputs, max_new_tokens=256):\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        repetition_penalty=1.5, #Avoid repetition.\n",
    "        early_stopping=False, #The model can stop before reach the max_length\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    " )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:12:56.063113Z",
     "iopub.status.busy": "2023-12-17T07:12:56.062397Z",
     "iopub.status.idle": "2023-12-17T07:12:58.297139Z",
     "shell.execute_reply": "2023-12-17T07:12:58.296278Z",
     "shell.execute_reply.started": "2023-12-17T07:12:56.063080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c6b9832e9140c1a873147a307eb7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b530d5246f4d8486c28893c6f4400e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea3edcb2e02481fa7752e8e817b22b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e8815ea2054a3988fb8c1aa8cb2a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d615341c314fe9bd65f618f31db1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    " model=foundation_model,\n",
    " args=training_args,\n",
    " train_dataset=dataset,\n",
    " peft_config = lora_config,\n",
    " dataset_text_field=\"text\",\n",
    " tokenizer=tokenizer,\n",
    " data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T07:13:10.322423Z",
     "iopub.status.busy": "2023-12-17T07:13:10.322063Z",
     "iopub.status.idle": "2023-12-17T17:02:56.516612Z",
     "shell.execute_reply": "2023-12-17T17:02:56.514903Z",
     "shell.execute_reply.started": "2023-12-17T07:13:10.322393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20231217_071354-o9lxqs99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/syedasad44/huggingface/runs/o9lxqs99' target=\"_blank\">iconic-serenity-14</a></strong> to <a href='https://wandb.ai/syedasad44/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/syedasad44/huggingface' target=\"_blank\">https://wandb.ai/syedasad44/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/syedasad44/huggingface/runs/o9lxqs99' target=\"_blank\">https://wandb.ai/syedasad44/huggingface/runs/o9lxqs99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 9:48:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.397500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.357900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.363700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.323400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.322000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.4036454681396484, metrics={'train_runtime': 35289.8796, 'train_samples_per_second': 0.283, 'train_steps_per_second': 0.283, 'total_flos': 1.3864437859995648e+17, 'train_loss': 0.4036454681396484, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T17:03:58.572590Z",
     "iopub.status.busy": "2023-12-17T17:03:58.571698Z",
     "iopub.status.idle": "2023-12-17T17:03:58.714595Z",
     "shell.execute_reply": "2023-12-17T17:03:58.713581Z",
     "shell.execute_reply.started": "2023-12-17T17:03:58.572555Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the model.\n",
    "\n",
    "peft_model_path = os.path.join(output_directory, f\"qlora_model\")\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:22:51.198554Z",
     "iopub.status.busy": "2023-12-25T14:22:51.198079Z",
     "iopub.status.idle": "2023-12-25T14:23:14.219860Z",
     "shell.execute_reply": "2023-12-25T14:23:14.218957Z",
     "shell.execute_reply.started": "2023-12-25T14:22:51.198521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe0099d1b5c49fbb8cd6a56c6315844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import peft\n",
    "from peft import AutoPeftModelForCausalLM, PeftConfig\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device_map = {\"\": 0}\n",
    "working_dir = '/kaggle/input/fine-tuning-urdu/Fine_tuning_urdu'\n",
    "\n",
    "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")\n",
    "peft_model_path = os.path.join(output_directory, f\"qlora_model\")\n",
    "\n",
    "#Load the Model.\n",
    "loaded_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    " peft_model_path,\n",
    " torch_dtype=torch.bfloat16,\n",
    " is_trainable=False,\n",
    " load_in_4bit=True,\n",
    " device_map = 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading sentences for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:23:24.564640Z",
     "iopub.status.busy": "2023-12-25T14:23:24.564255Z",
     "iopub.status.idle": "2023-12-25T14:23:24.629957Z",
     "shell.execute_reply": "2023-12-25T14:23:24.629160Z",
     "shell.execute_reply.started": "2023-12-25T14:23:24.564608Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/test-sentences/test_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:23:28.358247Z",
     "iopub.status.busy": "2023-12-25T14:23:28.357493Z",
     "iopub.status.idle": "2023-12-25T14:23:28.383419Z",
     "shell.execute_reply": "2023-12-25T14:23:28.382457Z",
     "shell.execute_reply.started": "2023-12-25T14:23:28.358194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>True Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Add appropriate punctuations and sentence boun...</td>\n",
       "      <td>وہ پہلے ایک بہت ہی ہمدرد کردار کی حیثیت سے نہی...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;Add appropriate punctuations ...</td>\n",
       "      <td>وہ پہلے ایک بہت ہی ہمدرد کردار کی حیثیت سے نہی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add appropriate punctuations and sentence boun...</td>\n",
       "      <td>میں نے اس سے پہلے کبھی نہیں سنا تھا اور نہ ہی ...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;Add appropriate punctuations ...</td>\n",
       "      <td>میں نے اس سے پہلے کبھی نہیں سنا تھا اور نہ ہی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add appropriate punctuations and sentence boun...</td>\n",
       "      <td>اس فلم کی خوبصورتی کا ثبوت ماں کی محبت کی طاقت...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;Add appropriate punctuations ...</td>\n",
       "      <td>اس فلم کی خوبصورتی کا ثبوت ماں کی محبت کی طاقت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Add appropriate punctuations and sentence boun...</td>\n",
       "      <td>اس فلم میں ایک ہندوستانی خاتون نندنی کی کہانی ...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;Add appropriate punctuations ...</td>\n",
       "      <td>اس فلم میں ایک ہندوستانی خاتون، نندنی کی کہانی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Add appropriate punctuations and sentence boun...</td>\n",
       "      <td>مقامات حیرت انگیز ہیں موسیقی حیرت انگیز ہے اور...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;Add appropriate punctuations ...</td>\n",
       "      <td>مقامات حیرت انگیز ہیں، موسیقی حیرت انگیز ہے، ا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Instructions  \\\n",
       "0  Add appropriate punctuations and sentence boun...   \n",
       "1  Add appropriate punctuations and sentence boun...   \n",
       "2  Add appropriate punctuations and sentence boun...   \n",
       "3  Add appropriate punctuations and sentence boun...   \n",
       "4  Add appropriate punctuations and sentence boun...   \n",
       "\n",
       "                                              Prompt  \\\n",
       "0  وہ پہلے ایک بہت ہی ہمدرد کردار کی حیثیت سے نہی...   \n",
       "1  میں نے اس سے پہلے کبھی نہیں سنا تھا اور نہ ہی ...   \n",
       "2  اس فلم کی خوبصورتی کا ثبوت ماں کی محبت کی طاقت...   \n",
       "3  اس فلم میں ایک ہندوستانی خاتون نندنی کی کہانی ...   \n",
       "4  مقامات حیرت انگیز ہیں موسیقی حیرت انگیز ہے اور...   \n",
       "\n",
       "                                                text  \\\n",
       "0  <s>[INST] <<SYS>>Add appropriate punctuations ...   \n",
       "1  <s>[INST] <<SYS>>Add appropriate punctuations ...   \n",
       "2  <s>[INST] <<SYS>>Add appropriate punctuations ...   \n",
       "3  <s>[INST] <<SYS>>Add appropriate punctuations ...   \n",
       "4  <s>[INST] <<SYS>>Add appropriate punctuations ...   \n",
       "\n",
       "                                          True Value  \n",
       "0  وہ پہلے ایک بہت ہی ہمدرد کردار کی حیثیت سے نہی...  \n",
       "1  میں نے اس سے پہلے کبھی نہیں سنا تھا اور نہ ہی ...  \n",
       "2  اس فلم کی خوبصورتی کا ثبوت ماں کی محبت کی طاقت...  \n",
       "3  اس فلم میں ایک ہندوستانی خاتون، نندنی کی کہانی...  \n",
       "4  مقامات حیرت انگیز ہیں، موسیقی حیرت انگیز ہے، ا...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on the sentences in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T14:23:34.710614Z",
     "iopub.status.busy": "2023-12-25T14:23:34.709575Z",
     "iopub.status.idle": "2023-12-25T18:56:46.888633Z",
     "shell.execute_reply": "2023-12-25T18:56:46.887479Z",
     "shell.execute_reply.started": "2023-12-25T14:23:34.710569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each row and apply the model\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    input_sentence = tokenizer(row['text'], return_tensors=\"pt\").to('cuda')\n",
    "    foundational_output_sentence = get_outputs(loaded_model, input_sentence)\n",
    "    decoded_output = tokenizer.batch_decode(foundational_output_sentence, skip_special_tokens=True)\n",
    "    df_test.at[index, 'output'] = decoded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T19:02:06.078706Z",
     "iopub.status.busy": "2023-12-25T19:02:06.077694Z",
     "iopub.status.idle": "2023-12-25T19:02:06.085211Z",
     "shell.execute_reply": "2023-12-25T19:02:06.084071Z",
     "shell.execute_reply.started": "2023-12-25T19:02:06.078670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST] <<SYS>>Add appropriate punctuations and sentence boundaries to the following Urdu text in input. Don't include any kind of html tags and don't truncate the output. Provide the actual input that has been asked. '،' '۔' These are the punctuations that need to be added<</SYS>>\\n وہ پہلے ایک بہت ہی ہمدرد کردار کی حیثیت سے نہیں آسکتی ہے لیکن پوری فلم کو دیکھ کر آپ چاہتے ہیں کہ اس کی کامیابی ہوجائے [/INST] \\nFollowing is the correct sentence: وہ پhlen أ earliest 4072 همDRRD کرดار کی حیظти سے نہیں آسکتی ہے، لیکن پوری フلم کو دیکھ کر آپ چاہتے ہیں كہ اس कي کاмаیابی ہوجائے۔ \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the updated DataFrame\n",
    "df_test.loc[0, 'output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T19:00:27.574771Z",
     "iopub.status.busy": "2023-12-25T19:00:27.574031Z",
     "iopub.status.idle": "2023-12-25T19:00:27.589854Z",
     "shell.execute_reply": "2023-12-25T19:00:27.588700Z",
     "shell.execute_reply.started": "2023-12-25T19:00:27.574736Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('urdu_test_fine_tuned.pkl', 'wb') as file:\n",
    "    pickle.dump(df_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4200314,
     "sourceId": 7249788,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4200349,
     "sourceId": 7249832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
